---
title: "Inferential Statistics: Sampling & Estimation"
output: html_notebook
---

Inferential statistics involves two major componenets - Estimation and Hypothesis Testing. This notebook will cover 'Estimation'. 

#### Revisiting Sampling theory

Before starting with Estimation, we need to understand the sampling theory, a part of which we've also covered in the first module.

It is necessary to understand what we're drawing inferences from (*sample*) and what we're drawing inferences about (*population*).
As we've previously discussed, **Population** refers to the set of all possible people, or all possible observations, that you want to draw conclusions about, and is generally much bigger than the sample.

If I am a cognitive scientist who wants to stude=y about the brain, what should I count as my population of interest:
- All undergraduate students in Psychology at IITK?
- All students at IITK?
- Any human in the world?
- Any intelligent being in the universe?

Do we know about our population of interest?

**Random Sample**
A procedure in which every member of the population has the same chance of being selected is called a simple random sample. We can say a process has an element of randomness whenever it is possible to repeat the process and get different answers each time.

If we can’t observe the same thing twice, the observations are said to have been sampled **without replacement**, else it is called sample **with replacement**.

Also recall the defiirent kind of **biases** that can occur during sampling.

**Types of sampling**

  - *Stratified sampling*: Suppose your population is (or can be) divided into several different subpopulations, or _strata_. For eg. you’re running a study at several different sites. Instead of trying to sample randomly from the population as a whole, you instead try to collect a separate random sample from each of the strata. An example would be two equally sample people from schizophrenic and non-schizophrenic populations while studying about schizophrenia. This is also referred to as _oversampling_ because it makes a deliberate attempt to over-represent rare groups.
  - *Snowball sampling*: It is especially useful when sampling from a “hidden” or hard to access population. For instance, suppose the researchers want to conduct an opinion poll among transgender people. For first round, they'll contact the people they know, for second one they'll get contacts of other people from the first set of participants and so on. Despite the advantage that we can get data in situations that might otherwise be impossible to get any, it makes the sample highly non-random and might also be unethical if not handled properly. This is because social networks are complex things, and just because we can use them to get data doesn’t always mean we should.
  - *Convenience sampling*: The samples are chosen in a way that is convenient to the researcher, and not selected at random from the population of interest. Eg. Snowball sampling or when undergraduates or all students if an institute are recruited for a study. 
  
  Can you think of other examples of convenience sampling in biology or psychology?
  
But are such sampling methods or biases wrong?

A bias in your sampling method is only a problem if it causes you to draw the wrong conclusions. We probably need it to be random only with respect to the psychologically/biologically-relevant phenomenon of interest.

##### Population parameters and sample statistics

To understand the relation between population parameters and sample statistics, let's take an example.

We want tos tudy the IQ of people. The population of interest is a group of actual humans who have IQ scores. Let's assume IQ tests are designed so that the average IQ is 100, the standard deviation of IQ scores is 15, and the distribution of IQ scores is normal. These values are referred to as the population parameters because they are characteristics of the entire population. In other words, population mean μ is 100, and the population standard deviation σ is 15.

Now imagine, we are running an experiment to estimate these population characteristics for which we will sample the population. 

```{r}
#Let's sample 100 IQ scores randomly from a population (assuming it has mean of 100, and sd of 15)
IQ <- rnorm(n = 100, mean = 100, sd = 15) # sample IQ scores (generate using rnorm)
IQ <- round(IQ) # IQs are whole numbers!
print(IQ) 
```

```{r}
#Let's also plot and see how it looks like
hist(IQ)
```

```{r}
#Find the mean of this sample
mean(IQ)
sd(IQ)
```

These are *sample statistics* which are properties of our data set, and although they are fairly similar to the true population values, they are not the same. 

What if we collect data from a large number of people?

**Law of large numbers**
```{r}
#Let's sample IQ from 10, 000 people
IQ <- rnorm(n = 10000, mean = 100, sd = 15) # sample IQ scores (generate using rnorm)
IQ <- round(IQ) # IQs are whole numbers!
```


```{r}
#Finding the mean and sd of this sample
mean(IQ)
sd(IQ)
```


```{r}
#Let's also plot a histogram
hist(IQ)
```

Even a mere inspection makes it clear that the larger sample is a much better approximation to the true population distribution than the smaller one. This is reflected in the sample statistics: the mean IQ for the larger sample turns out to be 99.94, and the standard deviation is 15.02. These values are now very close to the true population.

When applied to the sample mean, what the *law of large numbers* states is that as the sample gets larger, the sample mean tends to get closer to the true population mean. Or, to say it a little bit more precisely, as the sample size “approaches” infinity (written as N -> $\infty$) the sample mean approaches the population mean ($\bar{X}$ -> $\mu$).

But is sampling a large number of observations practically possible?

##### Central Limit Theorem

**Sampling distribution of mean**

Let's we can sample only 5 people at a time for their IQ.

```{r}
IQ.1 <- round(rnorm(n=5, mean = 100, sd = 15))
IQ.1
```

```{r}
# Finding the mean and sd of this sample
mean(IQ.1)
sd(IQ.1)
```

This is ofcourse much less accurat ethan our previous experiments with 100 and 10,000 samples. 

What if we decide to replicate this experiment? We will sample 5 people once again and find their IQs.

```{r}
IQ.2 <- round(rnorm(n=5, mean = 100, sd = 15))
IQ.2
mean(IQ.2)
sd(IQ.2)
```

Let's say we do 10 such replications

```{r}
IQ.3 <- round(rnorm(n=5, mean = 100, sd = 15))
IQ.4 <- round(rnorm(n=5, mean = 100, sd = 15))
IQ.5 <- round(rnorm(n=5, mean = 100, sd = 15))
IQ.6 <- round(rnorm(n=5, mean = 100, sd = 15))
IQ.7 <- round(rnorm(n=5, mean = 100, sd = 15))
IQ.8 <- round(rnorm(n=5, mean = 100, sd = 15))
IQ.9 <- round(rnorm(n=5, mean = 100, sd = 15))
IQ.10 <- round(rnorm(n=5, mean = 100, sd = 15))
```

If we replicate an experiment over and over again, what we end up with is a distribution of sample means! This distribution has a special name in statistics: it’s called the **sampling distribution of the mean**.

```{r}
mean_dist <- c(mean(IQ.1), 
               mean(IQ.2), 
               mean(IQ.3),
               mean(IQ.4),
               mean(IQ.5),
               mean(IQ.6),
               mean(IQ.7),
               mean(IQ.8),
               mean(IQ.9),
               mean(IQ.10))
hist(mean_dist) #Plotting the sampling distribution of the mean
```
```{r}
#Let's assume we replicated our sample 10,000 times. 
means <- 0 #Initializing vector
sd_norm <- 0
for (i in 1:10000) {
  IQ.n <- round(rnorm(n=100000, mean = 100, sd = 15))
  means[i] <- mean(IQ.n)
  sd_norm[i] <- sd(IQ.n)
  
}
mean_hist <- hist(means) #Plotting the sampling distribution of the mean
sd_hist <- hist(sd_norm)
plot(mean_hist$mids,mean_hist$density, type="l",col="blue",lwd=3)
plot(sd_hist$mids,sd_hist$density, type="l",col="blue",lwd=3)
```
```{r}
#Let's assume we replicated our sample 10,000 times. 
means <- 0 #Initializing vector
sd_norm <- 0
for (i in 1:10) {
  IQ.n <- round(rnorm(n=100, mean = 100, sd = 15))
  ssd.n <- sqrt(((IQ.n-mean(IQ.n))^2)/(length(IQ.n)))
  means[i] <- mean(IQ.n)
  sd_norm[i] <- sd(IQ.n)
  
}
hist(ssd)
hist(sd_norm)
#mean_hist <- hist(means) #Plotting the sampling distribution of the mean
#sd_hist <- hist(sd_norm)
#plot(mean_hist$mids,mean_hist$density, type="l",col="blue",lwd=3)
#plot(sd_hist$mids,sd_hist$density, type="l",col="blue",lwd=3)
```


```{r}
#Let's assume we replicated our sample a very large number of times. Warning: This code chunk might take a few minutes to run
means <- 0 #Initializing vector
for (i in 1:100000000) {
  IQ.n <- round(rnorm(n=5, mean = 100, sd = 15))
  means[i] <- mean(IQ.n)
}
hist(means) #Plotting the sampling distribution of the mean
```
A sampling distribution can exist for any sample statistic. 
 
For eg., think about the a sampling distribution for the largest IQ score i.e. the _maximum_ of a sample.
 
If you observe carefully, then you might have noticed the difference in the sampling distributions when sample size was 10 as compared to when sample size was 10,000. Try playing around with the sample size in the for loop above and notice the difference in plot.
 
**Central Limit Theorem**
 
The bigger the sample size, the narrower the sampling distribution gets. We can quantify this effect by calculating the standard deviation of the sampling distribution, which is referred to as the *standard error*.
The standard error of a statistic is often denoted SE, and since we’re usually interested in the standard error of the sample mean, we often use the acronym SEM. The sample size is denoted by N.

But what if the population distribution isn’t normal? What happens to the sampling distribution of the mean? 

The remarkable thing is this: no matter what shape your population distribution is, as N increases the sampling distribution of the mean starts to look more like a normal distribution.

Refer to _Section 10.3.3, Navarro D._ for further details.

It seems like we have evidence for all of the following claims about the sampling distribution of the mean:
 - The mean of the sampling distribution is the same as the mean of the population
 - The standard deviation of the sampling distribution (i.e., the standard error) gets smaller as the
sample size increases
 - The shape of the sampling distribution becomes normal as the sample size increases
 
The **Central Limit Theorem** proves all of the above statements. It also tells that if the population distribution has mean $\mu$ and standard deviation $\sigma$, then the sampling distribution of the mean also has mean $\mu$, and the standard error of the mean is $$SEM = \frac{\sigma}{\sqrt{N}}$$

#### Estimating population parameters

So far we assumed that the population mean is 100. How do we know that IQ scores have a true population mean of 100? 

Of course almost every research project of interest involves looking at a different population of people to those used in the test norms and so we’re going to have to estimate the population parameters from a sample of data. But how do we do this?

##### Estimating population mean

Let's say we want to estimate the IQ of people of Kanpur. We go to the Blue World water park and the tourists there are kind enough to participate in our study. Say, we get a mean $$\bar{X} = 98.5$$ for 100 locals.

But what is the true mean IQ for the entire population of Kanpur?

Here we can only calculate the *sample mean*, and use that as our estimate of the *population mean*. If true population mean is denoted $\mu$, then we would use $\hat{\mu}$ to refer to our estimate of the population mean. The sample mean is denoted $\bar{X}$ or sometimes _m_.

##### Estimating population standard deviation

What shall we use as our estimate for the standard deviation? Your first thought might be that we could do the same thing we did when estimating the mean, and just use the sample statistic as our estimate. That’s almost the right thing to do, but not quite.

Let's again think about the IQ experiment where we had assumed that population mean is 100 and standard deviation is 15. Say we only observe the IQ of 2 people and find the sample standard deviation. 

Let's plot the sampling distribution of the standard deviation.

```{r}
#Replicating 50 times 
sd_dist <- 0 #Initializing vector
for (i in 1:50) {
  IQ.n <- round(rnorm(n=2, mean = 100, sd = 15))
  sd_dist[i] <- sd(IQ.n)
}
hist(sd_dist) #Plotting the sampling distribution of the mean
```

If we take a look at the average of this distribution, we can clearly see it is quite far from 15 whereas if we find the average of the sampling distribution of mean of population, it is quite close to the popuation mean. Try it out your self.

```{r}
mean(sd_dist)
#Find the average for sampling distribution of population mean calculated above
```

On average, the average sample mean is equal to the population mean. It is an _unbiased estimator_, which is essentially the reason why the best estimate for the population mean is the sample mean. The plot on the right is quite different: on average, the sample standard deviation s is smaller than the population standard deviation $\sigma$. It is a _biased estimator_. In other words, if we want to make a “best guess” $\hat{\sigma}$ about the value of the population standard deviation $\sigma$, we should make sure our guess is a little bit larger than the sample standard deviation s.

How to fix this systematic bias?

Remember when we had talked about using N-1 instead of N for the calculation of standard deviation and variance?

That is what we do to correct the bias.

![est_var](fig1.png)

![est_sd](fig2.png)

The important variables at a glance:

![variables](fig3.png)


Okay, so far we have tried to estimate some of the population parameters. But how confidently can we say that this the correct estimate of the parameter? How can we quantify the amount of uncertainty associated with the estimate?

##### Estimating a confidence interval

If we say that there is a 95% chance that the true mean lies between 109 and 121, it is referred to as a **confidence interval** for the mean.

We also know that there is a 95% chance that a normally-distributed quantity will fall _approximately_ within two standard deviations of the true mean.

Let's find out what is the exact number?

```{r}
qnorm( p = c(.025, .975) )
```

This means that there is a 95% chance that a normally-distributed quantity will fall within 1.96 standard deviations of the true mean.

We now know that the standard deviation of the sampling distribution is referred to as the standard error, and the standard error of the mean is written as SEM. Therefore, we can say that there is a 95% probability that the _sample mean $\bar{X}$_ that we have actually observed lies within 1.96 standard errors of the population mean. Mathematically, we write this as:

$$ \mu - (1.96 \times SEM) \leqslant \bar{X} \leqslant \mu + (1.96 \times SEM) $$

But we want to know what to believe about the population parameters, given that we have observed a particular sample.

Using algebra, we can find that:

$$ \bar{X} - (1.96 \times SEM) \leqslant \mu \leqslant \bar{X} + (1.96 \times SEM) $$
This means that this range of values has a 95% probability of containing the population mean $\mu$. We refer to this range as a 95% confidence interval, denoted $CI_{95}$, calculated as 

$$ CI_{95} = \bar{X} \pm (1.96 \times \frac{\sigma}{\sqrt{N}}) $$

What would you to find out the range for 70% confidence interval? What percentiles would you require?

```{r}
#Try finding out the magic number (Eg. 1.96 for 95%) for 70% CI
```

But but but...

In the formula above we see that SEM is required which is calculated using population mean ($\sigma$) which we can only estimate ($\hat{\sigma}$. As a result, we need to use the quantiles of the t-distribution rather than the normal distribution to calculate our magic number; and the answer depends on the sample size.

```{r}
N <- 10000   # suppose our sample size is 10,000
qt( p = .975, df = N-1)   # calculate the 97.5th quantile of the t-dist
```

```{r}
#But if sample size is small:
N <- 10   # suppose our sample size is 10
qt( p = .975, df = N-1)   # calculate the 97.5th quantile of the t-dist
```

Bigger values mean that the confidence interval is wider, indicating that we’re more uncertain about what the true value of \mu actually is.

Can we interpret 95% confidence as a personal belief (*Bayesian view*) or is it something else (*Frequentist view*)?

Read _Section 10.5.2, Navarro D._ for detailed explanation on interpretation of Confidence intervals

Let's calculate the confidence interval from a dataset.

```{r}
install.packages('lsr')
library(lsr)
```


```{r}
load('afl24.Rdata')
ciMean( x = afl$attendance, conf = 0.95 ) #Calculating confidence interval using ciMean function from lsr package
```

```{r}
#Try finding the 80% confidence interval for the variable afl$home.score.
```

##### Plotting Confidence intervals

Let's quickly take a look at how to plot CIs.
For eg. if we want to plot the cofidence interval of afl$attendance

```{r}
install.packages('sciplot')
install.packages('gplots')
```

```{r}
library ('sciplot')  #bargraph.CI() and lineplot.CI()
library('gplots')    #plotmeans()
```

```{r}
#Here’s how to plot the means and confidence intervals drawn using bargraph.CI() from sciplot
bargraph.CI( x.factor = year,             # grouping variable
             response = attendance,       # outcome variable
             data = afl,                  # data frame with the variables
             ci.fun= ciMean,              # name of the function to calculate CIs
             xlab = "Year",               # x-axis label
             ylab = "Average Attendance") # y-axis label 

#Now plotting using lineplot.CI() function
lineplot.CI( x.factor = year,             # grouping variable
             response = attendance,       # outcome variable
             data = afl,                  # data frame with the variables
             ci.fun= ciMean,              # name of the function to calculate CIs
             xlab = "Year",               # x-axis label
             ylab = "Average Attendance") # y-axis label 

#A third type using plotmeans()

plotmeans( formula = attendance ~ year,  # outcome ~ group
           data = afl,                   # data frame with the variables
           n.label = FALSE)              # don’t show the sample sizes
```

*Reference: Chapter 10, Navarro D.*



