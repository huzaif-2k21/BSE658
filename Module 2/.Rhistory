library(performance)
model_performance(M1)
check_model(M1)
# Calculate residuals for the current model
residuals <- residuals(multiple_reg)
# Identify indices of residuals greater than 5 or less than -5
outliers <- which(abs(residuals) > 4)
# Create a new dataset excluding these outliers
cleaned_data <- original_data[-outliers, ]
# Calculate residuals for the current model
residuals <- residuals(multiple_reg)
# Identify indices of residuals greater than 5 or less than -5
outliers <- which(abs(residuals) > 4)
# Create a new dataset excluding these outliers
cleaned_data <- mtcars[-outliers, ]
# Refit the model with the cleaned dataset
multiple_reg_cleaned <- lm(mpg ~ hp + wt, data = cleaned_data)
# Check residuals histogram and normality again
hist(residuals(multiple_reg_cleaned), xlab = "Residuals", main = "", breaks = 10)
plot(multiple_reg_cleaned, which = 2)  # QQ plot
shapiro.test(residuals(multiple_reg_cleaned))  # Shapiro-Wilk test
# Calculate residuals for the current model
residuals <- residuals(multiple_reg)
# Identify indices of residuals greater than 5 or less than -5
outliers <- which((residuals) > 4)
# Create a new dataset excluding these outliers
cleaned_data <- mtcars[-outliers, ]
# Refit the model with the cleaned dataset
multiple_reg_cleaned <- lm(mpg ~ hp + wt, data = cleaned_data)
# Check residuals histogram and normality again
hist(residuals(multiple_reg_cleaned), xlab = "Residuals", main = "", breaks = 10)
plot(multiple_reg_cleaned, which = 2)  # QQ plot
shapiro.test(residuals(multiple_reg_cleaned))  # Shapiro-Wilk test
# Calculate residuals for the current model
residuals <- residuals(multiple_reg)
# Identify indices of residuals greater than 5 or less than -5
outliers <- which((residuals) > 4 | (residuals > -2 & residuals < -1))
# Create a new dataset excluding these outliers
cleaned_data <- mtcars[-outliers, ]
# Refit the model with the cleaned dataset
multiple_reg_cleaned <- lm(mpg ~ hp + wt, data = cleaned_data)
# Check residuals histogram and normality again
hist(residuals(multiple_reg_cleaned), xlab = "Residuals", main = "", breaks = 10)
plot(multiple_reg_cleaned, which = 2)  # QQ plot
shapiro.test(residuals(multiple_reg_cleaned))  # Shapiro-Wilk test
# Calculate residuals for the current model
residuals <- residuals(multiple_reg)
# Identify indices of residuals greater than 5 or less than -5
outliers <- which((residuals) > 4 & (residuals > -2 & residuals < -1))
# Create a new dataset excluding these outliers
cleaned_data <- mtcars[-outliers, ]
# Refit the model with the cleaned dataset
multiple_reg_cleaned <- lm(mpg ~ hp + wt, data = cleaned_data)
# Calculate residuals for the current model
residuals <- residuals(multiple_reg)
# Identify indices of residuals greater than 5 or less than -5
outliers <- which((residuals) > 4 | (residuals > -2 & residuals < -1))
# Create a new dataset excluding these outliers
cleaned_data <- mtcars[-outliers, ]
# Refit the model with the cleaned dataset
multiple_reg_cleaned <- lm(mpg ~ hp + wt, data = cleaned_data)
# Check residuals histogram and normality again
hist(residuals(multiple_reg_cleaned), xlab = "Residuals", main = "", breaks = 10)
plot(multiple_reg_cleaned, which = 2)  # QQ plot
shapiro.test(residuals(multiple_reg_cleaned))  # Shapiro-Wilk test
# Calculate residuals for the current model
residuals <- residuals(multiple_reg)
# Identify indices of residuals greater than 5 or less than -5
outliers <- which((residuals) > 4 )
# Create a new dataset excluding these outliers
cleaned_data <- mtcars[-outliers, ]
# Refit the model with the cleaned dataset
multiple_reg_cleaned <- lm(mpg ~ hp + wt, data = cleaned_data)
# Check residuals histogram and normality again
hist(residuals(multiple_reg_cleaned), xlab = "Residuals", main = "", breaks = 10)
plot(multiple_reg_cleaned, which = 2)  # QQ plot
shapiro.test(residuals(multiple_reg_cleaned))  # Shapiro-Wilk test
# Check linearity by plotting fitted values against observed values
yhat <- fitted.values(multiple_reg_cleaned)
plot(x = yhat, y = mtcars$mpg, xlab = "Fitted Values", ylab = "Observed Values")
# Check linearity by plotting fitted values against observed values
yhat <- fitted.values(multiple_reg_cleaned)
plot(x = yhat, y = cleaned_data$mpg, xlab = "Fitted Values", ylab = "Observed Values")
plot(multiple_reg, which = 1)
# Plot residuals to assess homogeneity of variance
plot(multiple_reg_cleaned, which = 3)
# Conduct non-constant variance score test
library(car)
ncvTest(multiple_reg_cleaned)
# Calculate VIF to check for multicollinearity among predictors
vif(multiple_reg_cleaned)
# Calculate VIF to check for multicollinearity among predictors
vif(multiple_reg)
# Calculate VIF to check for multicollinearity among predictors
vif(multiple_reg_cleaned)
# Start with a full model and perform backward elimination
full_model <- lm(mpg ~ hp + wt + cyl + disp, data = cleaned_data)
step(full_model, direction = "backward")
# Start with a null model and perform forward selection
null_model <- lm(mpg ~ 1, cleaned_data)
step(null_model, direction = "forward", scope = mpg ~ hp + wt + cyl + disp)
# Compare models with and without 'cyl' using AIC and ANOVA
M0 <- lm(mpg ~ hp + wt, cleaned_data)
M1 <- lm(mpg ~ hp + wt + cyl, cleaned_data)
AIC(M0, M1)
anova(M0, M1)
# Compare models with and without 'cyl' using AIC and ANOVA
M0 <- lm(mpg ~ hp + wt, mtcars)
M1 <- lm(mpg ~ hp + wt + cyl, mtcars)
AIC(M0, M1)
anova(M0, M1)
# Compare models with and without 'cyl' using AIC and ANOVA
M0 <- lm(mpg ~ hp + wt, cleaned_data)
M1 <- lm(mpg ~ hp + wt + cyl, cleaned_data)
AIC(M0, M1)
anova(M0, M1)
# Load easystats package and assess model performance
library(performance)
model_performance(M1)
check_model(M1)
multiple_reg <- lm(mpg ~ hp + wt, data = cleaned_data)
print(multiple_reg)
summary(multiple_reg)
multiple_reg <- lm(mpg ~ hp + wt, data = mtcars)
print(multiple_reg)
summary(multiple_reg)
# Load easystats package and assess model performance
multiple_reg <- lm(mpg ~ hp + wt, data = cleaned_data)
print(multiple_reg)
summary(multiple_reg)
library(performance)
model_performance(M1)
check_model(M1)
library(lme4)
library(magrittr)
library(tidyverse)
library(ggplot2)
library(lmerTest)
data("sleepstudy")
head(sleepstudy)
sleep2 <- sleepstudy %>%
filter(Days >= 2) %>%
mutate(days_deprived = Days - 2)
ggplot(sleep2, aes(x = days_deprived,
y = Reaction)) +
geom_point() +
scale_x_continuous(breaks = 0:7) +
facet_wrap(~Subject) +
labs(y = "Reaction Time",
x = "Days deprived of sleep (0 = baseline)")
cp_model <- lm(Reaction ~ days_deprived, sleep2)
summary(cp_model)
ggplot(sleep2, aes(x = days_deprived, y = Reaction)) +
geom_abline(intercept = coef(cp_model)[1],
slope = coef(cp_model)[2],
color = '#f4cae2', size = 1.5) +
geom_point() +
scale_x_continuous(breaks = 0:7) +
facet_wrap(~Subject, nrow = 3) +
labs(y = "Reaction Time",
x = "Days deprived of sleep (0 = baseline)")
View(sleepstudy)
sleep2 %>% pull(Subject) %>% is.factor()
np_model <- lm(Reaction ~ days_deprived + Subject + days_deprived:Subject,
data = sleep2)
summary(np_model)
all_intercepts <- c(coef(np_model)["(Intercept)"],
coef(np_model)[3:19] + coef(np_model)["(Intercept)"])
all_slopes  <- c(coef(np_model)["days_deprived"],
coef(np_model)[20:36] + coef(np_model)["days_deprived"])
ids <- sleep2 %>% pull(Subject) %>% levels() %>% factor()
np_coef <- tibble(Subject = ids,
intercept = all_intercepts,
slope = all_slopes)
ggplot(sleep2, aes(x = days_deprived, y = Reaction)) +
geom_abline(data = np_coef,
mapping = aes(intercept = intercept,
slope = slope),
color = '#f4cae2', size = 1.5) +
geom_point() + theme_bw() +
scale_x_continuous(breaks = 0:7) +
facet_wrap(~Subject, nrow=3) +
labs(y = "Reaction Time",
x = "Days deprived of sleep (0 = baseline)")
pp_mod <- lmer(Reaction ~ days_deprived + (days_deprived | Subject), sleep2)
summary(pp_mod)
newdata <- crossing(
Subject = sleep2 %>% pull(Subject) %>% levels() %>% factor(),
days_deprived = 0:7)
newdata2 <- newdata %>%
mutate(Reaction = predict(pp_mod, newdata))
ggplot(sleep2, aes(x = days_deprived, y = Reaction)) +
geom_line(data = newdata2,
color = '#f4cae2', size = 1.5) +
geom_point() + theme_bw() +
scale_x_continuous(breaks = 0:7) +
facet_wrap(~Subject, nrow = 3) +
labs(y = "Reaction Time",
x = "Days deprived of sleep (0 = baseline)")
knitr::opts_chunk$set(echo = TRUE)
data("airquality")  # Load the dataset
airquality <- na.omit(airquality)  # Remove rows with NA values
lm_simple <- lm(Ozone ~ Temp, data = airquality)
summary(lm_simple)
data("airquality")  # Load the dataset
airquality <- na.omit(airquality)  # Remove rows with NA values
head(airquality)
lm_null <- lm(Ozone ~ 1, data = airquality)  # Start with an empty model
lm_full <- lm(Ozone ~ Temp + Solar.R + Wind + Month, data = airquality)  # Full model with all predictors
forward_model <- step(lm_null, scope = list(lower = lm_null, upper = lm_full), direction = "forward")
summary(forward_model)
backward_model <- step(lm_full, direction = "backward")
summary(backward_model)
plot(forward_model, which = 2)  # QQ plot for residuals
shapiro.test(residuals(forward_model))  # Shapiro-Wilk test for normality
plot(x=lm_full, which = 2)  # QQ plot for residuals
shapiro.test(residuals(lm_full))  # Shapiro-Wilk test for normality
residuals( object = lm_full )
#checking for the outliers using cooks distance
cks <- cooks.distance( model = lm_full)
cks
plot(lm_full,which=4)
hist( x = residuals(lm_full),   # data are the residuals
xlab = "Value of residual",      # x-axis label
main = "",                       # no title
breaks = 20                      # lots of breaks
)
yhat.2 <- fitted.values( object = lm_full)
plot( x = yhat.2,
y = airquality$Ozone,
xlab = "Fitted Values",
ylab = "Observed Values"
)
knitr::opts_chunk$set(echo = TRUE)
---
title: "Comparison of Full Data and Limited Data with Bootstrapping in Regression"
```{r setup, include=FALSE}
# Load necessary libraries
if (!require(car)) install.packages('car')
if (!require(dplyr)) install.packages('dplyr')
if (!require(boot)) install.packages('boot')
library(car)
library(dplyr)
library(boot)
# Load the mtcars dataset
data("mtcars")
# Full OLS regression on the complete dataset
full_model <- lm(mpg ~ wt + hp + cyl, data = mtcars)
summary(full_model)
confint(full_model)
View(mtcars)
data()
data("diamonds")
# Load the diamonds dataset
data("diamonds")
# Convert cut and color to numeric factors for regression
diamonds$cut <- as.numeric(diamonds$cut)
diamonds$color <- as.numeric(diamonds$color)
# Full OLS regression on the complete dataset
full_model <- lm(price ~ carat + cut + color, data = diamonds)
summary(full_model)
confint(full_model)
View(diamonds)
# Filter out rows with NA in relevant columns
flights_filtered <- flights %>%
filter(!is.na(arr_delay), !is.na(dep_delay), !is.na(air_time), !is.na(distance))
if (!require(nycflights13)) install.packages('nycflights13')
library(nycflights13)
# Filter out rows with NA in relevant columns
flights_filtered <- flights %>%
filter(!is.na(arr_delay), !is.na(dep_delay), !is.na(air_time), !is.na(distance))
# Full OLS regression on the complete dataset
full_model <- lm(arr_delay ~ dep_delay + air_time + distance, data = flights_filtered)
summary(full_model)
confint(full_model)
# Sample approximately 25 rows of the original data
limited_data <- flights_filtered %>% sample_n(25)
nrow(limited_data)
# Regression on the limited dataset
limited_model <- lm(arr_delay ~ dep_delay + air_time + distance, data = limited_data)
summary(limited_model)
confint(limited_model)
# Define a function to extract coefficients from bootstrapped samples
boot_fn <- function(data, indices) {
sample_data <- data[indices, ]
model <- lm(arr_delay ~ dep_delay + air_time + distance, data = sample_data)
return(coef(model))
}
# Perform bootstrapping with 1000 resamples
set.seed(123)
boot_results <- boot(data = limited_data, statistic = boot_fn, R = 1000)
# Calculate bootstrapped confidence intervals for 'dep_delay' coefficient
boot_ci_dep_delay <- boot.ci(boot_results, type = "norm", index = 2)
print(boot_ci_dep_delay)
# Repeat this for other coefficients by changing the index if desired
# Define a function to extract coefficients from bootstrapped samples
boot_fn <- function(data, indices) {
sample_data <- data[indices, ]
model <- lm(arr_delay ~ dep_delay + air_time + distance, data = sample_data)
return(coef(model))
}
# Perform bootstrapping with 1000 resamples
set.seed(123)
boot_results <- boot(data = limited_data, statistic = boot_fn, R = 1000)
print(confint(boot_results, level = 0.95, type = "norm"))
hist(boot_results)
# Calculate bootstrapped confidence intervals for 'dep_delay' coefficient
boot_ci_dep_delay <- boot.ci(boot_results, type = "norm", index = 2)
print(boot_ci_dep_delay)
# Repeat this for other coefficients by changing the index if desired
# Define a function to extract coefficients from bootstrapped samples
boot_fn <- function(data, indices) {
sample_data <- data[indices, ]
model <- lm(arr_delay ~ dep_delay + air_time + distance, data = sample_data)
return(coef(model))
}
# Perform bootstrapping with 1000 resamples
set.seed(123)
boot_results <- boot(data = limited_data, statistic = boot_fn, R = 1000)
print(confint(boot_results, level = 0.95, type = "norm"))
summary(confint(boot_results, level = 0.95, type = "norm"))
hist(boot_results)
# Calculate bootstrapped confidence intervals for 'dep_delay' coefficient
boot_ci_dep_delay <- boot.ci(boot_results, type = "norm", index = 2)
print(boot_ci_dep_delay)
# Repeat this for other coefficients by changing the index if desired
The summary of results :
knitr::opts_chunk$set(echo = TRUE)
orthodont_null_model <- lmer(distance ~ 1 + (1 | Subject), data = orthodont1)
# Install packages if they are not already installed
if (!require("nlme")) install.packages("nlme")
if (!require("lme4")) install.packages("lme4")
if (!require("easystats")) install.packages("easystats")
if (!require("dplyr")) install.packages("dplyr")
if (!require("sjPlot")) install.packages("sjPlot")
# Load packages
library(nlme)
library(lme4)
library(easystats)
library(dplyr)
library(sjPlot)
# Load the Orthodont dataset
data("Orthodont", package = "nlme")
# Quick view of the data
head(Orthodont)
# Summary statistics
summary(Orthodont)
library(ggplot2)
orthodont1 <- Orthodont %>%
mutate(Sex = as.factor(Sex),age=as.factor(age),
Subject = as.factor(Subject))
boxplot(distance ~ age*Sex,
col=c("white","lightgray"),orthodont1)
orthodont1 %>% ggplot(aes(x= distance, y=Sex)) +
geom_boxplot()
orthodont1 %>% ggplot(aes(x= distance, y=age)) +
geom_boxplot()
orthodont1 %>% ggplot(aes(x= distance, y=Sex)) +
geom_boxplot() + facet_grid(.~Subject) +coord_flip()
orthodont_null_model <- lmer(distance ~ 1 + (1 | Subject), data = orthodont1)
summary(orthodont_null_model)
orthodont_model1 <- lmer(distance ~ Sex + (1 | Subject), data = orthodont1)
# Display the summary of the model
summary(orthodont_model1)
orthodont_model2 <- lmer(distance ~ Sex +Age + (1 | Subject), data = orthodont1)
orthodont_model2 <- lmer(distance ~ Sex +age + (1 | Subject), data = orthodont1)
# Display the summary of the model
summary(orthodont_model2)
AIC(orthodont_null_model,orthodont_model1,orthodont_model2)
orthodont_null_model_1 <- lmer(distance ~ 1 + (1 | Subject), data = orthodont1, REML = FALSE)
orthodont_model1_1 <- lmer(distance ~ Sex + (1 | Subject), data = orthodont1, REML = FALSE)
orthodont_model2_1 <- lmer(distance ~ Sex +age + (1 | Subject), data = orthodont1, REML = FALSE)
anova(orthodont_null_model_1, orthodont_model1_1, orthodont_model2_1)
orthodont_model3 = lmer(distance~Sex + age + (1|Subject) , data = orthodont1, REML=FALSE)
summary(orthodont_model3)
anova( orthodont_model1_1, orthodont_model2_1,orthodont_model3)
orthodont_model3 = lmer(distance~Sex + age + (1+Sex|Subject) , data = orthodont1, REML=FALSE)
summary(orthodont_model3)
anova( orthodont_model1_1, orthodont_model2_1,orthodont_model3)
knitr::opts_chunk$set(echo = TRUE)
data = read.csv("http://www.bodowinter.com/tutorial/politeness_data.csv")
head(data)
data = data %>% mutate(attitude=as.factor(attitude), gender=as.factor(gender), subject=as.factor(subject))
boxplot(frequency ~ attitude*gender,
col=c("white","lightgray"),data)
politeness.model0 = lmer(frequency ~ 1 + (1|subject) + (1|scenario), data=data)
summary(politeness.model0)
politeness.model1 = lmer(frequency ~ attitude + (1|subject) + (1|scenario), data=data)
summary(politeness.model1)
politeness.model2 = lmer(frequency ~ attitude + gender + (1|subject) + (1|scenario), data=data)
summary(politeness.model2)
AIC(politeness.model0, politeness.model1, politeness.model2)
politeness.null = lmer(frequency ~ 1 + (1|subject) + (1|scenario), data=data, REML=FALSE)
politeness.partial = lmer(frequency ~ attitude + (1|subject) + (1|scenario), data=data, REML=FALSE)
politeness.full = lmer(frequency ~ attitude + gender + (1|subject) + (1|scenario), data=data, REML=FALSE)
anova(politeness.null, politeness.partial, politeness.full)
politeness.model3 = lmer(frequency~attitude + gender + (1|subject) + (1+attitude|scenario), data = data, REML=FALSE)
summary(politeness.model3)
anova(politeness.null, politeness.partial, politeness.full, politeness.model3)
coef(orthodont_model3)
orthodont_null_model <- lmer(distance ~ 1 + (1 | Subject) +(1|age), data = orthodont1)
summary(orthodont_null_model)
orthodont_null_model <- lmer(distance ~ 1 + (1 | Subject) +(1|Sex), data = orthodont1)
summary(orthodont_null_model)
orthodont_model1 <- lmer(distance ~ age + (1 | Subject) +(1|Sex), data = orthodont1)
# Display the summary of the model
summary(orthodont_model1)
AIC(orthodont_null_model,orthodont_model1)
orthodont_null_model_1 <- lmer(distance ~ 1 + (1 | Subject) +(1|Sex), data = orthodont1, REML = FALSE)
orthodont_model1_1 <- lmer(distance ~ age + (1 | Subject) +(1|Sex), data = orthodont1, REML = FALSE)
anova(orthodont_null_model_1, orthodont_model1_1)
orthodont_model3 = lmer(distance~ age +(1|Subject) +(1+age|Sex) , data = orthodont1, REML=FALSE)
summary(orthodont_model3)
anova( orthodont_model1_1, orthodont_model2_1,orthodont_model3)
anova( orthodont_model1_1,orthodont_model3)
orthodont_null_model <- lmer(distance ~ 1 + (1 | Subject), data = orthodont1)
summary(orthodont_null_model)
orthodont_model1 <- lmer(distance ~ Sex + (1 | Subject), data = orthodont1)
# Display the summary of the model
summary(orthodont_model1)
orthodont_model2 <- lmer(distance ~ Sex +age + (1 | Subject), data = orthodont1)
# Display the summary of the model
summary(orthodont_model2)
AIC(orthodont_null_model,orthodont_model1,orthodont_model2)
orthodont_null_model_1 <- lmer(distance ~ 1 + (1 | Subject), data = orthodont1, REML = FALSE)
orthodont_model1_1 <- lmer(distance ~ Sex + (1 | Subject), data = orthodont1, REML = FALSE)
orthodont_model2_1 <- lmer(distance ~ Sex +age + (1 | Subject), data = orthodont1, REML = FALSE)
anova(orthodont_null_model_1, orthodont_model1_1, orthodont_model2_1)
orthodont_model3 = lmer(distance~Sex + age + (1+Sex|Subject) , data = orthodont1, REML=FALSE)
summary(orthodont_model3)
anova( orthodont_model1_1, orthodont_model2_1,orthodont_model3)
anova( orthodont_model1_1, orthodont_model2_1,orthodont_model3)
AIC( orthodont_model1_1, orthodont_model2_1,orthodont_model3)
AIC(politeness.null, politeness.partial, politeness.full, politeness.model3)
orthodont_model3 = lmer(distance~age + Sex + (1+age|Subject) , data = orthodont1, REML=FALSE)
orthodont_model3 = lmer(distance~Sex + age + (1+Sex|Subject) , data = orthodont1, REML=FALSE)
summary(orthodont_model3)
check_normality(orthodont_model2_1)
check_normality(politeness.full)
check_heteroscedasticity(orthodont_model2_1)
check_collinearity(orthodont_model2_1)
check_heteroscedasticity(politeness.full)
check_collinearity(politeness.full)
check_model(orthodont_model2_1)
# Install packages if they are not already installed
if (!require("nlme")) install.packages("nlme")
if (!require("lme4")) install.packages("lme4")
if (!require("easystats")) install.packages("easystats")
if (!require("dplyr")) install.packages("dplyr")
if (!require("sjPlot")) install.packages("sjPlot")
# Load packages
library(nlme)
library(lme4)
library(easystats)
library(dplyr)
library(sjPlot)
library(tidyverse)
library(broom)
library(car)
# Load the Orthodont dataset
data("Orthodont", package = "nlme")
orthodont_data <- Orthodont
orthodont_data <- orthodont_data %>%
mutate(age = factor(age))
orthodont_data %>%
group_by(age) %>%
summarize(mean_distance = mean(distance), sd_distance = sd(distance))
orthodont_data %>%
ggplot(aes(x = age, y = distance, fill = age)) +
geom_boxplot() +
theme_minimal() +
scale_fill_brewer(palette = 'Set3') +
labs(title = "Boxplot of Distance by Age", x = "Age (Categorical)", y = "Distance")
distance_model_age <- lm(distance ~ age, data = orthodont_data)
summary(distance_model_age)
age_preds <- tibble(age = unique(orthodont_data$age))
age_preds$fit <- predict(distance_model_age, age_preds)
age_preds
orthodont_data1 <- orthodont_data %>%
mutate(age = factor(age),
age_releveled = relevel(age, ref = '10'))  # Set age 10 as the reference
# Verify levels for age and age_releveled
levels(orthodont_data1$age)
levels(orthodont_data1$age_releveled)
# Run the linear model with re-leveled age as the predictor
distance_model_age_releveled <- lm(distance ~ age_releveled, data = orthodont_data1)
summary(distance_model_age_releveled)
orthodont_data1 <- orthodont_data %>%
mutate(age = factor(age),
age_releveled = relevel(age, ref = '14'))  # Set age 10 as the reference
# Verify levels for age and age_releveled
levels(orthodont_data1$age)
levels(orthodont_data1$age_releveled)
# Run the linear model with re-leveled age as the predictor
distance_model_age_releveled <- lm(distance ~ age_releveled, data = orthodont_data1)
summary(distance_model_age_releveled)
shapiro.test(residuals(distance_model_age))
hist(residuals(distance_model_age), main = "Histogram of Residuals", xlab = "Residuals")
plot(distance_model_age, which = 2)
shapiro.test(residuals(distance_model_age))
hist(residuals(distance_model_age), main = "Histogram of Residuals", xlab = "Residuals")
plot(distance_model_age, which = 2)
ncvTest(distance_model_age)
residualPlots( model = distance_model_age)
AIC( orthodont_model1_1, orthodont_model2_1,orthodont_model3)
tinytex::install_tinytex()
tinytex::uninstall_tinytex()
install.packages('tinytex')
tinytex::install_tinytex()
tinytex::install_tinytex()
tinytex::pdflatex('test.tex')
tinytex::install_tinytex()
